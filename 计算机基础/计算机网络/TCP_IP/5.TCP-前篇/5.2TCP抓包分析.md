在TCP的理论前提上，通过搭建测试环境并抓取数据包，可以更加直观的认识TCP的连接、数据传输过程，进一步提升对 TCP 可靠传输相关特性的认识。

## 1.显形“不可见”的网络包

借助两大分析网络的利器：**tcpdump 和 Wireshark**，可使网络世界中肉眼看不见的数据包显形。

> 二者有何区别？

tcpdump 和 Wireshark 都是常用的网络抓包和分析工具，可用来**分析网络性能**。

- tcpdump 仅支持命令行格式使用，常用在 Linux 服务器中；
- Wireshark 除了可以抓包，还提供了可视化分析网络包的图形页面。

二者可搭配使用：先用 tcpdump 命令在 Linux 服务器上抓包，接着把抓包文件拖出到 Windows 电脑后，用 Wireshark 进行可视化分析。

当然，如果只是在 Windows 上抓包，只用 Wireshark 工具就可以。

> tcpdump 在 Linux 下如何抓包？

tcpdump 提供了大量的选项以及各式各样的过滤表达式，以抓取指定的数据包。但只需掌握一些常用选项和过滤表达式，就可以满足大部分场景的需要了。

举个抓取`ping包`的栗子：

![](..\imgs\ping数据包.jpg)

ping 的数据包是 `icmp` 协议，所以在使用 tcpdump 抓包的时候，可以指定只抓 icmp 协议的数据包：

```bash
# -i eth1 表示抓取eth1网口的数据包
# icmp 表示抓取icmp协议的数据包
# host 表示主机过滤，抓取对应IP的数据包
# -nn 表示不解析IP地址和端口号的名称
tcpdump -i eth1 icmp and host 183.232.231.174 -nn
```

当 tcpdump 抓取到 icmp 数据包后， 输出格式如下：

```go
时间戳 协议 源地址.源端口 > 目的地址.目的端口 网络包详细信息
```

![img](..\imgs\icmp抓包内容.jpg)

从抓包结果可以清楚看到 `icmp echo` 的交互过程。首先发送方发起了 `ICMP echo request` 请求报文，接收方收到后回了一个 `ICMP echo reply` 响应报文，之后 `seq` 是递增的。

一些常用的抓包方法参考如下表格。

> 常用选项类

![](..\imgs\tcpdump常用选项.jpg)

> 常用过滤表达式

![tcpdump 常用过滤表达式类](..\imgs\tcpdump过滤表达式.jpg)

tcpdump 虽然功能强大，但输出的格式并不直观。

所以，在工作中 tcpdump 只是用来抓取数据包，而后把 tcpdump 抓取的数据包保存成 `pcap` 后缀的文件，接着用 Wireshark 工具进行分析。

> Wireshark 如何分析数据包？

Wireshark 除了可以抓包外，还提供了可视化分析网络包的图形页面，同时，还内置了一系列的汇总分析工具。

比如，拿上面的 ping 例子来说，可以如下命令把抓取的数据包保存到 ping.pcap 文件：

```bash
tcpdump -i eth1 icmp and host 183.232.231.174 -w ping.pcap
```

接着把 ping.pcap 文件拖到Windows主机并用 Wireshark 打开它：

![](..\imgs\wireshark解析pcap.jpg)

如图。在 Wireshark 的页面里，不仅展示各个网络包的头部信息，还会用不同的颜色来区分不同的协议。由于这次抓包只有 ICMP 协议，所以只有紫色的条目。

接着，在网络包列表中选择某一个网络包后，在其下面的网络包详情中，**可以更清楚的看到，这个网络包在协议栈各层的详细信息**。比如，以编号 1 的网络包为例子：

![](..\imgs\ping网络包.jpg)

- 数据链路层可以看到 MAC 包头信息，如源 MAC 地址和目标 MAC 地址等字段；
-  IP 层可以看到 IP 包头信息，如源 IP 地址和目标 IP 地址、TTL、IP 包长度、协议等 IP 协议各个字段的数值和含义；
-  ICMP 层可以看到 ICMP 包头信息，比如 Type、Code 等 ICMP 协议各个字段的数值和含义。

Wireshark 用了分层的方式，展示了各个层的包头信息，把“不可见”的数据包，清清楚楚的展示了出来。用好这个工具可以帮我们更好的学习计算机网络技术。

ping 的例子告诉我们，网络分层就像有序的分工，每一层都有自己的责任范围和信息，上层协议完成工作后就交给下一层，最终形成一个完整的网络包。

![](..\imgs\网络分层协作流程.jpg)

## 2.解密TCP三次握手和四次挥手

本小节抓取和分析 HTTP 协议网络包，理解 TCP 三次握手和四次挥手的工作原理。

启动本地服务器，在**终端一**用 `tcpdump` 命令抓取数据包：

```bash
# 客户端执行 tcpdump 抓包
$ tcpdump -i any tcp and host 127.0.0.1 and port 80 -w http.pcap
```

**终端二**执行下面的 curl 命令：

```bash
# 客户端执行curl
$ curl http://127.0.0.1
```

回到终端一，按下 Ctrl+C 停止 tcpdump，并把得到的 `http.pcap` 取出到电脑。并使用 Wireshark 打开：

![](..\imgs\wireshark抓包解析.jpg)

Wireshark 可以用**时序图**的方式显示数据包交互的过程，依次点选菜单栏 -> 统计 (Statistics) -> 流量图 (Flow Graph)，在弹出的界面中的「流量类型」选择 「TCP Flows」，可以清晰看到整个过程中 TCP 流的执行过程：

![](..\imgs\TCP流量图.jpg)

> 为什么三次握手连接过程的 Seq 是 0 ？

Wireshark 工具做了优化，默认显示的序列号 seq 是`相对值`，而不是真实值。

如果想看到实际的序列号的值，可以依次点选右键菜单 -> 协议首选项 -> Relative Seq -> 取消：

![](..\imgs\seq显示真实值.jpg)

之后 Seq 显示的就是真实值了：

![](..\imgs\seq真实值显示结果.jpg)

可见，客户端和服务端的序列号实际上是不同的，序列号是一个随机值。

可对比前面理论部分 TCP 三次握手和四次挥手的流程加深理解：

![](..\imgs\TCP三次握手四次挥手流程.jpg)

> 为什么抓到的 TCP 挥手是三次？

当被动关闭方（上图的服务端）在 TCP 挥手过程中，「**没有数据要发送」并且「开启了 TCP 延迟确认机制」，那么第二和第三次挥手就会合并传输，这样就出现了三次挥手。**

而通常情况下，服务器端收到客户端的 `FIN` 后，很可能还没发送完数据，所以就会先回复客户端一个 `ACK` 包，稍等一会儿，完成所有数据包的发送后，才会发送 `FIN` 包，这也就是四次挥手了。

## 3.TCP三次握手异常

本小节将带着这些问题开始实验：

- TCP 第一次握手的 SYN 丢包，会发生什么？
- TCP 第二次握手的 SYN、ACK 丢包，会发生什么？
- TCP 第三次握手的 ACK 丢包，会发生什么？

直观来说丢包就会**重传**，进一步的：

- 会重传几次？
- 超时重传的时间 RTO 会如何变化？
- 在 Linux 下如何设置重传次数？
- ....

### 3.1实验场景

本次实验使用两台虚拟机，一台作为服务端，一台作为客户端：

![](..\imgs\实验用虚拟机.jpg)

客户端和服务器（`apache web服务`）都是 CentOs 6.5 Linux，Linux 内核版本 2.6.32。

### 3.2实验一：第一次握手SYN丢包

为了模拟 TCP 第一次握手 SYN 丢包的情况，可以在拔掉服务器的网线后，立刻在客户端执行 curl 命令：

```go
# 客户端发起curl请求
$ date;curl http://192.168.12.36;date
Sat May 16 12:47:22 CST 2023
```

其间 tcpdump 抓包的命令如下：

```go
# 客户端执行 tcpdump,抓取访问服务端的HTTP数据包
$ tcpdump -i eth0 tcp and host 192.168.12.36 and port 80 -w tcp_sys_timeout.pcap
```

过了一会， curl 返回了超时连接的错误：

```go
$ date;curl http://192.168.12.36;date
Sat May 16 12:47:22 CST 2023
curl: (7) Failed to connect to 192.168.12.36 port 80: Connection timed out
Sat May 16 12:48:25 CST 2023
```

从 `date` 返回的时间，可以发现在超时接近 1 分钟的时间后，curl 返回了错误。

接着，把 tcp_sys_timeout.pcap 文件用 Wireshark 打开分析，显示如下图：

![](..\imgs\SYN超时重传5次.jpg)

从上图可以发现， 客户端发起了 SYN 包后，一直没有收到服务端的 ACK ，所以一直超时重传，共 5 次，分别发生在：1 秒、 3 秒、 7 秒、15 秒、 31 秒，即每次超时时间 RTO 是**指数（翻倍）上涨的**，当超过最大重传次数后，客户端不再发送 SYN 包。

在 Linux 中，第一次握手的 `SYN` 超时重传次数，是如下内核参数指定的：

```bash
# 默认值为 5，即 SYN 最大重传次数是 5 次
$ cat /proc/sys/net/ipv4/tcp_syn_retries
5
```

继续实验，把 `tcp_syn_retries` 设置为 2 次：

```bash
$ echo 2 > /proc/sys/net/ipv4/tcp_syn_retries
```

重传抓包后，用 Wireshark 打开分析：

![](..\imgs\SYN超时重传2次.jpg)

> 小结

当客户端发起的 TCP 第一次握手 SYN 包，在超时时间内没收到服务端的 ACK，就会超时重传 SYN 数据包。每次超时重传的 RTO 是翻倍上涨的，直到 SYN 包的重传次数到达 `tcp_syn_retries` 值后停止。

![](..\imgs\第1次握手丢失.png)

### 3.3实验二：第二次握手SYN、ACK丢包

给客户端加上防火墙限制，直接丢弃来自服务端的数据。防火墙的配置如下：

```bash
# 客户端配置的防火墙规则
iptables -I INPUT -s 192.168.12.36 -j DROP
```

接着，在客户端执行curl命令：

```go
$ date;curl http://192.168.12.36;date
Sat May 16 13:20:18 CST 2023
curl: (7) Failed to connect to 192.168.12.36 port 80: Connection timed out
Sat May 16 13:21:21 CST 2023
```

从 `date` 返回的时间前后，可以算出大概 1 分钟后，curl 报错退出了。

客户端在这其间抓取的数据包，用 Wireshark 打开分析，时序图如下：

![](..\imgs\第二次握手丢包分析.jpg)

分析：

- 客户端发起 SYN 后，由于防火墙屏蔽了服务端的所有数据包，所以 curl 无法收到服务端的 SYN、ACK 包，当发生超时后，就会重传 SYN 包；
- 服务端收到客户的 SYN 包后，就会回 SYN、ACK 包，但是客户端一直没有回 ACK，服务端在超时后，重传了 SYN、ACK 包，**接着一会，客户端超时重传的 SYN 包又抵达了服务端，服务端收到后，回了 SYN、ACK 包，但是SYN、ACK包的重传定时器并没有重置，还持续在重传，因为第二次握手在没收到第三次握手的 ACK 确认报文时，会继续重传，直到达到重传到最大次数。**
- 最后，客户端 SYN 超时重传次数达到了 5 次（tcp_syn_retries 默认值 5 次），就不再继续发送 SYN 包了。

所以，我们可以发现，**当第二次握手的 SYN、ACK 丢包时，客户端会超时重发 SYN 包，服务端也会超时重传 SYN、ACK 包。**

> 客户端设置了防火墙，屏蔽了服务端的网络包，为什么 tcpdump 还能抓到服务端的网络包？

添加 iptables 限制后， tcpdump 是否能抓到包 ，要看添加的 iptables 限制条件：

- 如果添加的是 `INPUT` 规则，则可以抓得到包
- 如果添加的是 `OUTPUT` 规则，则抓不到包

网络包进入主机后的顺序如下：

- 进来的顺序 Wire -> NIC -> **tcpdump -> netfilter/iptables**
- 出去的顺序 **iptables -> tcpdump** -> NIC -> Wire

> 第二次握手 SYN、ACK 限制最大重传次数是多少？

TCP 第二次握手 SYN、ACK 包的最大重传次数由 `tcp_synack_retries` 内核参数限制：

```bash
# 默认是 5 次
$ cat /proc/sys/net/ipv4/tcp_synack_retries
5
```

继续实验，验证 SYN、ACK 包最大重传次数是 5 次。

把客户端的 `tcp_syn_retries` 设置为 1，表示客户端 SYN 最大超时次数是 1 次，防止多次重传 SYN，把服务器 SYN、ACK 超时定时器重置。

接着重复上面的步骤：

1. 客户端配置防火墙屏蔽服务端的数据包
2. 客户端 tcpdump 抓取 curl 执行时的数据包

把抓取的数据包，用 Wireshark 打开分析，时序图如下：

![](..\imgs\服务端SYN超时重传时序图.jpg)

分析：

- 客户端的 SYN 只超时重传了 1 次，因为 `tcp_syn_retries` 值为 1
- 服务端应答了客户端超时重传的 SYN 包后，由于一直收不到客户端的 ACK 包，所以超时重传 SYN、ACK 包，每次的 RTO 也是指数上涨的，一共超时重传了 5 次，因为 `tcp_synack_retries` 值为 5

接着把 **tcp_synack_retries 设置为 2**，`tcp_syn_retries` 依然为 1:

```go
$ echo 2 > /proc/sys/net/ipv4/tcp_synack_retries
$ echo 1 > /proc/sys/net/ipv4/tcp_syn_retries
```

依然保持一样的实验步骤进行操作：

![](..\imgs\服务端SYN超时重传2.jpg)

可见：

- 客户端的 SYN 包只超时重传了 1 次，符合 tcp_syn_retries 设置的值；
- 服务端的 SYN、ACK 超时重传了 2 次，符合 tcp_synack_retries 设置的值

> 小结

若 TCP 第二次握手 SYN、ACK 丢包，客户端 SYN 包会超时重传，服务端 SYN、ACK 也会超时重传。

客户端 SYN 包超时重传的最大次数，是由 tcp_syn_retries 决定的，默认值是 5 次；服务端 SYN、ACK 包时重传的最大次数，是由 tcp_synack_retries 决定的，默认值是 5 次。

> 疑问：客户端超时重传，服务端收到之后，是不是上一个包的重传syn/ack就停止了?

### 3.4实验三：第三次握手ACK丢包

在服务端配置防火墙，屏蔽客户端 TCP 报文中标志位是 ACK 的包，即丢弃客户端的 ACK 报文。iptables 配置命令如下：

```bash
# 服务端配置防火墙
$ iptables -I INPUT -s 192.168.12.37 -p tcp --tcp-flag ACK ACK -j DROP
```

接着，在客户端执行如下tcpdump命令：

```bash
# 客户端执行tcpdump抓取数据包
tcpdump -i eth0 tcp and host 192.168.12.36 and port 80 -w tcp_thir_ack_timeout.pcap
```

然后，客户端向服务端发起 telnet，它会发起 TCP 连接：

```bash
# 客户端执行telnet
$ telnet 192.168.12.36 80
Trying 192.168.12.36...
Connected to 192.168.12.36.
Escape character is '^]'.
		   # 阻塞中...
```

此时，由于服务端收不到第三次握手的 ACK 包，所以一直处于 `SYN_RECV` 状态：

```bash
# 服务端执行 netstat
$ netstat -napt | grep 192.168.12.37
tcp  0  0 192.168.12.36:80    192.168.12.37:36008    SYN_RECV  -
```

而客户端是已完成 TCP 连接建立，处于 `ESTABLISHED` 状态：

```bash
# 客户端执行 netstat
$ netstat -napt | grep 192.168.12.36
tcp  0  0 192.168.12.37:36008    192.168.12.36:80    ESTABLISHED 8844/telnet
```

过了 1 分钟后，观察发现服务端的 TCP 连接不见了：

```bash
# 服务端执行 netstat
$ netstat -napt | grep 192.168.12.37
$             
# 显示空白，说明服务端刚处于SYN_RECV状态的TCP连接不见了
```

过了 30 分钟，客户端依然还是处于 `ESTABLISHED` 状态：

```bash
# 客户端执行 netstat
$ netstat -napt | grep 192.168.12.36
tcp  0  0 192.168.12.37:36008    192.168.12.36:80    ESTABLISHED 8844/telnet
```

接着，在刚才客户端建立的 telnet 会话，输入 123456 字符，进行发送：

```bash
# 客户端执行telnet
$ telnet 192.168.12.36 80
Trying 192.168.12.36...
Connected to 192.168.12.36.
Escape character is '^]'.
123456    # 输入字符
		  # 阻塞中...
```

持续「好长」一段时间，客户端的 telnet 才断开连接：

```bash
# 客户端执行telnet
$ telnet 192.168.12.36 80
Trying 192.168.12.36...
Connected to 192.168.12.36.
Escape character is '^]'.
123456    # 输入字符
Connection closed by foreign host.		  # 断开连接的错误
```

以上就是本次的实现的现象，这里存在两个疑点：

- 为什么服务端原本处于 `SYN_RECV` 状态的连接，过 1 分钟后就消失了？
- 为什么客户端 telnet 输入 123456 字符后，过了好长一段时间，telnet 才断开连接？

把刚抓的数据包用 Wireshark 打开分析，时序图如下：

![](..\imgs\第三次握手丢包时序图.jpg)

分析：

- 客户端发送 SYN 包给服务端，服务端收到后，回了个 SYN、ACK 包给客户端，此时服务端的 TCP 连接处于 `SYN_RECV` 状态；
- 客户端收到服务端的 SYN、ACK 包后，给服务端回了个 ACK 包，此时客户端的 TCP 连接处于 `ESTABLISHED` 状态；
- 由于服务端配置了防火墙，屏蔽了客户端的 ACK 包，所以服务端一直处于 `SYN_RECV` 状态，没有进入 `ESTABLISHED` 状态，tcpdump 之所以能抓到客户端的 ACK 包，是因为数据包进入系统的顺序是先进入 tcpudmp，后经过 iptables；
- 接着，服务端超时重传了 SYN、ACK 包，重传了 5 次后，也就是**超过 tcp_synack_retries 的值（默认值是 5），然后就没有继续重传了，此时服务端的 TCP 连接主动中止了，所以刚才处于 SYN_RECV 状态的 TCP 连接断开了**，而客户端依然处于`ESTABLISHED` 状态；
- 虽然服务端 TCP 断开了，但过了一段时间，发现客户端依然处于`ESTABLISHED` 状态，于是就在客户端的 telnet 会话输入了 123456 字符；
- 由于服务端的防火墙配置了屏蔽所有携带 ACK 标志位的 TCP 报文，客户端发送的数据报文，服务端并不会接收，而是丢弃（如果服务端没有设置防火墙，由于服务端已经断开连接，此时收到客户的发来的数据报文后，会回 RST 报文）。客户端由于一直收不到数据报文的确认报文，所以触发超时重传，在超时重传过程中，每一次重传，RTO 的值是指数增长的，所以持续了好长一段时间，客户端的 telnet 才报错退出了，此时共重传了 15 次，然后客户端的也断开了连接。

通过这一波分析，刚才的两个疑点已经解除了：

- 服务端在重传 SYN、ACK 包时，超过了最大重传次数 `tcp_synack_retries`，于是服务端的 TCP 连接主动断开了。
- 客户端向服务端发送数据报文时，如果迟迟没有收到数据包的确认报文，也会触发超时重传，一共重传了 15 次数据报文， 最后 telnet 就断开了连接。

> TCP 建立连接后的数据包最大超时重传次数由什么参数指定？

该次数由 `tcp_retries2` 指定，默认值是 15 次：

```bash
$ cat /proc/sys/net/ipv4/tcp_retries2
15
```

如果 15 次重传都做完了，TCP 就会告诉应用层说：“搞不定了，包怎么都传不过去！”

> 如果客户端不发送数据，什么时候才会断开处于 ESTABLISHED 状态的连接？

这就需要 TCP 的 **保活机制**：

定义一个时间段，期间如果没有任何连接相关的活动，TCP 保活机制每隔一个时间间隔，会发送一个「探测报文」，它包含的数据非常少。如果连续几个探测报文都没有得到响应，则认为当前的 TCP 连接已经死亡，系统内核将错误信息通知给上层应用程序。

Linux 内核有对应的参数可以设置保活时间、保活探测的次数、保活探测的时间间隔：

```bash
# 保活时间默认7200秒 即2小时内如果没有任何连接相关的活动，就会启动保活机制
net.ipv4.tcp_keepalive_time=7200
# 每次检测间隔 75 秒
net.ipv4.tcp_keepalive_intvl=75 
# 检测 9 次无响应，认为对方是不可达的，从而中断本次的连接。
net.ipv4.tcp_keepalive_probes=9
```

也就是说在 Linux 系统中，最少需要经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接。

```bash
# 7200 + (75 * 9) = 7875s
tcp_keepalive_time + (tcp_keepalive_intvl * tcp_keepalive_probes)
```

如果抓包足够久，或许能抓到探测报文。

> 小结

建立 TCP 连接时，如果第三次握手的 ACK，服务器无法收到，则会**短暂处于** `SYN_RECV` 状态，而客户端会处于 `ESTABLISHED` 状态。

服务端一直收不到 TCP 第三次握手的 ACK，就会一直重传 SYN、ACK 包，直到重传次数超过 `tcp_synack_retries` 值（默认 5 次），断开 TCP 连接。

而客户端则会有两种情况：

- 如果客户端没发送数据包，一直处于 `ESTABLISHED` 状态，然后经过 2 小时 11 分 15 秒才可以发现一个「死亡」连接，于是客户端连接就会断开连接。
- 如果客户端发送了数据包，一直没有收到服务端对该数据包的确认报文，则会一直重传该数据包，直到重传次数超过 `tcp_retries2` 值（默认15 次），客户端就会断开 TCP 连接。

## 4.TCP快速建立连接

客户端在向服务端发起 HTTP GET 请求时，一个完整的交互过程，需要 2.5 个 RTT 的时延。

由于第三次握手是可以携带数据的，这时如果在第三次握手发起 HTTP GET 请求，需要 2 个 RTT 的时延。

但是在下一次（不是同个 TCP 连接的下一次）发起 HTTP GET 请求时，经历的 RTT 也是一样，如下图：

![](..\imgs\常规HTTP请求.jpg)

在 Linux 3.7 内核版本中，提供了 TCP Fast Open 功能，这个功能可以减少 TCP 连接建立的时延。

![](..\imgs\fast-open时延.jpg)

- 第一次建立连接的时候，服务端在第二次握手时生成一个 加密`Cookie` 并通过 SYN、ACK 包一起发给客户端，客户端会缓存这个 `Cookie`，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延；
- 在下次请求的时候，客户端在 SYN 包带上 `Cookie` 发给服务端，就提前可以跳过三次握手的过程，因为 `Cookie` 中维护了一些信息，服务端可以从 `Cookie` 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延；

注：客户端在请求并存储了 Fast Open Cookie 之后，可以不断重复 TCP Fast Open 直至服务器认为 Cookie 无效（通常为过期）。

> 在 Linux 上如何打开 Fast Open 功能？

可以通过设置 `net.ipv4.tcp_fastopen` 内核参数，来打开 Fast Open 功能：

- 0 关闭
- 1 作为客户端使用 Fast Open 功能
- 2 作为服务端使用 Fast Open 功能
- 3 无论作为客户端还是服务器，都可以使用 Fast Open 功能

> TCP Fast Open 抓包分析

如图，数据包 7 号，客户端发起了第二次 TCP 连接时，SYN 包会携带 Cooike，并且长度为 5 的数据。

服务端收到后，校验 Cooike 合法，于是就回了 SYN、ACK 包，并且确认应答收到了客户端的数据包，ACK = 5 + 1 = 6

![](..\imgs\fast-open抓包分析.jpg)

## 5.TCP重复确认和快速重传

当接收方收到乱序数据包时，会发送重复的 ACK，以便告知发送方重发该数据包，**当发送方收到 3 个重复 ACK 时，就会触发快速重传，立刻重发丢失数据包。**

![](..\imgs\TCP快速重传机制.jpg)

TCP 重复确认和快速重传的一个案例，用 Wireshark 分析如下：

![](..\imgs\TCP快速重传抓包分析.jpg)

- 数据包 1 期望的下一个数据包 Seq 是 1，但是数据包 2 发送的 Seq 却是 10945，说明收到的是乱序数据包，于是回了数据包 3 ，还是同样的 Seq = 1，Ack = 1，这表明是重复的 ACK；
- 数据包 4 和 6 依然是乱序的数据包，于是依然回了重复的 ACK；
- 当对方收到三次重复的 ACK 后，于是就快速重传了 Seq = 1 、Len = 1368 的数据包 8；
- 当收到重传的数据包后，发现 Seq = 1 是期望的数据包，于是就发送了个确认收到快速重传的 ACK

注意：快速重传和重复 ACK 标记信息是 Wireshark 的功能，非数据包本身的信息。

以上案例在 TCP 三次握手时协商开启了**选择性确认 SACK**，因此一旦数据包丢失并收到重复 ACK ，即使在丢失数据包之后还成功接收了其他数据包，也只需要重传丢失的数据包。如果不启用 SACK，就必须重传丢失包之后的每个数据包。

如果要支持 `SACK`，必须双方都要支持。在 Linux 下，可以通过 `net.ipv4.tcp_sack` 参数打开这个功能（Linux 2.4 后默认打开）。

## 6.TCP流量控制

TCP **滑动窗口**机制可以防止发送方无脑的发送数据，导致接收方缓冲区被填满。这也是**流量控制**的原理：利用接收方的接收窗口来控制发送方要发送的数据量。

接收窗口是由接收方指定的值，存储在 TCP 头部中，告诉发送方自己的 TCP 缓冲空间区大小，这个缓冲区是给应用程序读取数据的空间：

- 如果应用程序读取了缓冲区的数据，那么缓冲空间区就会把被读取的数据移除；
- 如果应用程序没有读取数据，则数据会一直滞留在缓冲区。

接收窗口的大小，是在 TCP 三次握手中协商好的，后续数据传输时，接收方发送确认应答 ACK 报文时，会携带当前的接收窗口的大小，以此来告知发送方。

假设接收方接收到数据后，应用层能很快的从缓冲区里读取数据，那么窗口大小会一直保持不变，过程如下：

![](..\imgs\理想状态下滑动窗口的变化.jpg)

但现实中服务器会出现繁忙的情况，当应用程序读取速度慢，缓存空间就会慢慢被占满，于是为了保证发送方发送的数据不超过缓冲区大小，服务器会调整窗口大小的值，接着通过 ACK 报文通知给对方，告知现在的接收窗口大小，从而控制发送方发送的数据大小。

![](..\imgs\服务器繁忙时滑动窗口的变化.jpg)

### 6.1零窗口通知与窗口探测

假设接收方处理数据的速度跟不上接收数据的速度，缓存就会被占满，从而导致接收窗口为 0，当发送方接收到零窗口通知时，就会停止发送数据。

如下图，可以看到接收方的窗口大小在不断的收缩至 0：

![](..\imgs\接收方窗口收缩.jpg)

接着，发送方会**定时发送窗口大小探测报文**，以便及时知道接收方窗口大小的变化。

以下图 Wireshark 分析图作为例子说明：

![](..\imgs\零窗口与窗口探测.jpg)

- 发送方发送了数据包 1 给接收方，接收方收到后，由于缓冲区被占满，回了个零窗口通知；
- 发送方收到零窗口通知后，就不再发送数据了，直到过了 `3.4` 秒后，发送了一个 TCP Keep-Alive 报文，也就是窗口大小探测报文；
- 当接收方收到窗口探测报文后，就立马回一个窗口通知，但是窗口大小还是 0；
- 发送方发现窗口还是 0，于是继续等待了 `6.8`（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回了窗口为 0 的通知；
- 发送方发现窗口还是 0，于是继续等待了 `13.5`（翻倍） 秒后，又发送了窗口探测报文，接收方依然还是回了窗口为 0 的通知；

可以发现，这些窗口探测报文以 3.4s、6.5s、13.5s 的间隔出现，说明**超时时间会翻倍递增**。

这连接暂停了 25s，想象一下你在打王者的时候，25s 的延迟你还能上王者吗?

### 6.2发送窗口的分析

> 在 Wireshark 看到的 Windows size 也就是 " win = "，这个值表示发送窗口吗？

这不是发送窗口，而是在向对方声明自己的接收窗口。

你可能会好奇，抓包文件里有「Window size scaling factor」，它其实是算出实际窗口大小的乘法因子，「Window size value」实际上并不是真实的窗口大小，真实窗口大小的计算公式如下：

「Window size value」 * 「Window size scaling factor」 = 「Caculated window size 」

对应的下图案例，也就是 32 * 2048 = 65536。

![](..\imgs\窗口大小计算.jpg)

实际上是 Caculated window size 的值是 Wireshark 工具算好的，Window size scaling factor 和 Windos size value 的值是在 TCP 头部中，其中 Window size scaling factor 是在三次握手过程中确定的，如果抓包的数据没有 TCP 三次握手，那可能就无法算出真实的窗口大小的值，如下图：

![](..\imgs\窗口大小无法计算的情况.jpg)

> 如何在包里看出发送窗口的大小？

很遗憾，没有简单的办法，发送窗口虽然是由接收窗口决定，但是它又可以被网络因素影响，也就是拥塞窗口，实际上发送窗口是值是 min(拥塞窗口，接收窗口)。

> 发送窗口和 MSS 有什么关系？

发送窗口决定了一口气能发多少字节，而 MSS 决定了这些字节要分多少包才能发完。

举个例子，如果发送窗口为 16000 字节的情况下，如果 MSS 是 1000 字节，那就需要发送 1600/1000 = 16 个包。

> 发送方在一个窗口发出 n 个包，是不是需要 n 个 ACK 确认报文？

不一定，因为 TCP 有累计确认机制，所以当收到多个数据包时，只需要应答最后一个数据包的 ACK 报文就可以了。

### 6.3TCP延迟确认与Nagle算法

当TCP 报文的承载的数据非常小的时候(例如几个字节)，那么整个网络的效率是很低的，因为每个 TCP 报文中都会有 20 个字节的 TCP 头部，也会有 20 个字节的 IP 头部，而数据只有几个字节，所以在整个报文中有效数据占有的比重就会非常低。

这就好像快递员开着大货车送一个小包裹一样浪费。

那么就出现了常见的两种策略，来减少小报文的传输，分别是：**Nagle 算法**、**延迟确认**。

> Nagle 算法如何避免大量 TCP 小数据报文的传输？

Nagle 算法做了一些策略来避免过多的小数据报文发送，这可提高传输效率。具体可以参考[这篇文章](.\5.1TCP可靠传输.md)中的糊涂窗口综合症小节。

![](..\imgs\Nagle算法.jpg)

上图右侧启用了 Nagle 算法，它的发送数据的过程：

- 一开始由于没有已发送未确认的报文，所以就立刻发了 H 字符；
- 接着，在还没收到对 H 字符的确认报文时，发送方就一直在囤积数据，直到收到了确认报文后，此时没有已发送未确认的报文，于是就把囤积后的 ELL 字符一起发给了接收方；
- 待收到对 ELL 字符的确认报文后，于是把最后一个 O 字符发送了出去

可以看出，**Nagle 算法一定会有一个小报文，也就是在最开始的时候。**

另外，Nagle 算法默认是打开的，如果对于一些需要小数据包交互的场景的程序，比如，telnet 或 ssh 这样的**交互性比较强的程序，则需要关闭 Nagle 算法**。

可以在 Socket 设置 `TCP_NODELAY` 选项来关闭这个算法（关闭 Nagle 算法没有全局参数，需要根据每个应用自己的特点来关闭）。

```bash
# 关闭Nagle算法
setsockopt(sock_fd,IPPROTO_TCP,TCP_NODELAY,(char *)&value,sizeof(int));
```

> 那延迟确认又是什么？

事实上当没有携带数据的 ACK，它的网络效率也是很低的，因为它也有 40 个字节的 IP 头 和 TCP 头，但却没有携带数据报文。

为了解决 ACK 传输效率低问题，所以就衍生出了 **TCP 延迟确认**。

TCP 延迟确认的策略：

- 当有响应数据要发送时，ACK 会随着响应数据一起立刻发送给对方；
- 当没有响应数据要发送时，ACK 将会延迟一段时间，以等待是否有响应数据可以一起发送；
- 如果在延迟等待发送 ACK 期间，对方的第二个数据报文又到达了，这时就会立刻发送 ACK。

![](..\imgs\TCP延迟确认.jpg)

延迟等待的时间是在 Linux 内核中定义的：

```bash
#define TCP_DELACK_MAX ((unsigned)(HZ/5)) #最大延迟确认时间
#define TCP_DELACK_MIN ((unsigned)(HZ/25)) #最小延迟确认时间
```

关键就需要 `HZ` 这个数值大小，HZ 是跟系统的时钟频率有关，每个操作系统都不一样，在我的 Linux 系统中 HZ 大小是 `1000`，如下图：

```bash
$ cat /boot/config-2.6.32-431.el6.x86_64 | grep '^CONFIG_HZ='
CONFIG_HZ=1000
```

知道了 HZ 的大小，那么就可以算出：

- 最大延迟确认时间是 `200` ms （1000/5）
- 最短延迟确认时间是 `40` ms （1000/25）

TCP 延迟确认可以在 Socket 设置 `TCP_QUICKACK` 选项来关闭这个算法。

```bash
# 关闭TCP延迟确认
setsockopt(sock_fd,IPPROTO_TCP,TCP_QUICKACK,(char *)&value,sizeof(int));
```

> 延迟确认 和 Nagle 算法混合使用时，会产生新的问题

当 TCP 延迟确认 和 Nagle 算法混合使用时，会导致时耗增长，如下图：

![](..\imgs\TCP延迟确认与Nagle混合使用.jpg)

发送方使用了 Nagle 算法，接收方使用了 TCP 延迟确认会发生如下的过程：

- 发送方先发出一个小报文，接收方收到后，由于延迟确认机制，自己又没有要发送的数据，只能干等着发送方的下一个报文到达；
- 而发送方由于 Nagle 算法机制，在未收到第一个报文的确认前，是不会发送后续的数据；
- 所以接收方只能等待最大时间 200 ms 后，才回 ACK 报文，发送方收到第一个报文的确认报文后，也才可以发送后续的数据。

很明显，这两个同时使用会造成额外的时延，这就会使得网络"很慢"的感觉。

要解决这个问题，只有两个办法：

- 要不发送方关闭 Nagle 算法
- 要不接收方关闭 TCP 延迟确认

## Q&A

>  tcp_retries1 参数，是什么场景下生效？ tcp_retries2是只受限于规定的次数，还是受限于次数和时间限制的最小值？

tcp_retries1和tcp_retries2都是在TCP三次握手之后的场景。

- 当重传次数超过tcp_retries1就会指示 IP 层进行 MTU 探测、刷新路由等过程，并不会断开TCP连接，当重传次数超过 tcp_retries2 才会断开TCP流。
- tcp_retries1 和 tcp_retries2 两个重传次数都是受一个 timeout 值限制的，timeout 的值是根据它俩的值计算出来的，当重传时间超过 timeout，就不会继续重传了，即使次数还没到达。

> tcp_orphan_retries也是控制tcp连接的关闭。这个跟tcp_retries1 tcp_retries2有什么区别？

主动方发送 FIN 报文后，连接就处于 FIN_WAIT1 状态下，该状态通常应在数十毫秒内转为 FIN_WAIT2。如果迟迟收不到对方返回的 ACK 时，此时，内核会定时重发 FIN 报文，其中重发次数由 tcp_orphan_retries 参数控制。

> 为什么连续两个报文的seq会是一样的呢，比如三次握手之后的那个报文？还是说，序号相同的是同一个报文，只是拆开显示了？

1. 三次握手中的前两次，是 seq+1；
2. 三次握手中的最后一个 ack，实际上是可以携带数据的，文章的例子是没有发送数据的，你可以看到第三次握手的 len=0 ，在数据传输阶段「下一个 seq=seq+len 」，所以第三次握手的 seq 和下一个数据报的 seq 是一样的，因为 len 为 0。
